import torch
import torch.nn.functional as F
import torch.nn as nn
import json
from PIL import Image
import matplotlib.pyplot as plt
import os

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ======= 1ï¸âƒ£ ìµœì¢… ì„ë² ë”© ë¡œë”© =======
print("ğŸ”¹ ì„ë² ë”© ë¡œë”© ì¤‘...")
completed_korean = torch.load("/home/aikusrv01/C-MCR/completed_korean.pt").to(DEVICE)
completed_image = torch.load("/home/aikusrv01/C-MCR/completed_image.pt").to(DEVICE)

print(f"âœ… Korean Embedding Shape: {completed_korean.shape}")
print(f"âœ… Image Embedding Shape: {completed_image.shape}")

# âœ… QueryëŠ” 1ê°œì˜ ë¬¸ì¥ì— ëŒ€í•œ ì„ë² ë”©ì´ì–´ì•¼ í•¨
if completed_korean.dim() > 1 and completed_korean.size(0) > 1:
    print("ğŸ”¹ Query ì„ë² ë”©ì˜ ì²« ë²ˆì§¸ ë²¡í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    completed_korean = completed_korean[0].unsqueeze(0)

print(f"âœ… Query Shape (Korean): {completed_korean.shape}")

# ======= 2ï¸âƒ£ Embedding ë¡œë”© =======
print("ğŸ”¹ Embedding ë¡œë”© ì¤‘...")
korean_emb = torch.load("/home/aikusrv01/C-MCR/korean_embedding.pt").to(DEVICE)
image_emb = torch.load("/home/aikusrv01/C-MCR/image_embedding.pt").to(DEVICE)

# ğŸ”¸ ğŸŸ¢ Transpose ì œëŒ€ë¡œ ìˆ˜í–‰í•˜ê¸°
if korean_emb.shape[0] == 768:  
    print("ğŸ”¸ Transpose ì§„í–‰ ì¤‘...")
    korean_emb = korean_emb.transpose(0, 1).contiguous()  # (768, 616767) â†’ (616767, 768)
    print(f"âœ… Transpose í›„ Shape: {korean_emb.shape}")

# ğŸ”¹ Korean Embedding ì°¨ì› ì¡°ì •
print("ğŸ”¹ Korean Embedding ì°¨ì› ì¡°ì • ì¤‘...")
project_korean = nn.Linear(768, 512).to(DEVICE)
korean_emb = project_korean(korean_emb)
print(f"âœ… Korean Embedding Shape after Projection: {korean_emb.shape}")
print(f"âœ… Image Embedding Shape: {image_emb.shape}")

# ğŸ”¹ ì „ì²´ Korean Memory ë¡œë”© ì¤‘...
print("ğŸ”¹ ì „ì²´ Korean Memory ë¡œë”© ì¤‘...")
all_korean_emb = torch.load("/home/aikusrv01/C-MCR/korean_embedding.pt").to(DEVICE)

# ğŸ”¸ ë©”ëª¨ë¦¬ì—ì„œ Transposeë¥¼ í™•ì‹¤íˆ ë°˜ì˜
if all_korean_emb.shape[0] == 768:
    print("ğŸ”¸ Transpose ì§„í–‰ ì¤‘...")
    all_korean_emb = all_korean_emb.transpose(0, 1).contiguous()
    print(f"âœ… Transpose í›„ Shape: {all_korean_emb.shape}")

# ğŸ”¹ Korean Memory ì°¨ì› ì¡°ì •
print("ğŸ”¹ Korean Memory ì°¨ì› ì¡°ì • ì¤‘...")
all_korean_emb = project_korean(all_korean_emb)
print(f"âœ… íˆ¬ì˜ ì™„ë£Œ! New Shape: {all_korean_emb.shape}")

# ğŸ”¸ Korean Memory ì €ì¥
torch.save(all_korean_emb, "/home/aikusrv01/C-MCR/completed_korean.pt")
print(f"âœ… ì „ì²´ Korean Memory ì €ì¥ ì™„ë£Œ! (Shape: {all_korean_emb.shape})")

top_k = 5
# ======= 3ï¸âƒ£ Text â†’ Korean Text ê²€ìƒ‰ =======
print("\nğŸ” Text â†’ Korean Text ê²€ìƒ‰ ì¤‘...")

# ğŸ”¹ Korean Memory ë¡œë”©
korean_memory = torch.load("/home/aikusrv01/C-MCR/completed_korean.pt").to(DEVICE)

# ğŸ”¹ ìœ ì‚¬ë„ ê³„ì‚° (Cosine Similarity)
similarity_korean = F.cosine_similarity(completed_korean, korean_memory)

# ğŸ”¹ ìƒìœ„ 5ê°œ ê²€ìƒ‰
values_ko, indices_ko = torch.topk(similarity_korean, top_k, largest=True)

# ğŸ”¹ ê²°ê³¼ ì¶œë ¥
print("\nğŸ”¹ [Text â†’ Korean Text] ê²€ìƒ‰ ê²°ê³¼ (Top 5):")
for rank, (score, idx) in enumerate(zip(values_ko, indices_ko)):
    print(f"{rank + 1}. Korean Text Index: {idx.item()}, Similarity: {score.item()}")

# ======= 4ï¸âƒ£ ì‹¤ì œ í•œêµ­ì–´ ë¬¸ì¥ ë¡œë”© ë° ë§¤ì¹­ =======
korean_texts_path = "/home/aikusrv01/C-MCR/datasets/MSCOCO_korean/MSCOCO_train_val_Korean.json"

print("\nğŸ” ì‹¤ì œ í•œêµ­ì–´ ë¬¸ì¥ í™•ì¸ ì¤‘...")
with open(korean_texts_path, "r", encoding="utf-8") as f:
    data = json.load(f)

# ğŸ”¸ JSONì˜ ê¸¸ì´ í™•ì¸
max_index = len(data)
print(f"âœ… JSON ë°ì´í„° ê°œìˆ˜: {max_index}")

# ğŸ”¹ ìƒìœ„ 5ê°œì˜ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í•œêµ­ì–´ ë¬¸ì¥ ì¶œë ¥
for rank, idx in enumerate(indices_ko):
    if idx.item() >= max_index:
        print(f"âš ï¸ ê²½ê³ : Index {idx.item()}ê°€ JSON ê¸¸ì´ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        continue
    print(f"{rank + 1}. Index {idx.item()} â†’ Korean Text: {data[idx.item()]['caption_ko']}")
