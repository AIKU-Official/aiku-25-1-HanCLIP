# í”„ë¡œì íŠ¸ëª…

ğŸ“¢ 2025ë…„ 1í•™ê¸° [AIKU](https://github.com/AIKU-Official) í™œë™ìœ¼ë¡œ ì§„í–‰í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤
ğŸ‰ 2025ë…„ 1í•™ê¸° AIKU Conference ì—´ì‹¬íˆìƒ ìˆ˜ìƒ!

## ì†Œê°œ

> **HanCLIP**: A lightweight and efficient cross-lingual vision-language model for Korean, built on top of CLIP

**HanCLIP**ì€ ëŒ€ê·œëª¨ í•œêµ­ì–´â€“ì´ë¯¸ì§€ ìŒ ì—†ì´ë„ í•œêµ­ì–´ì™€ ì‹œê° ì •ë³´ ê°„ ì˜ë¯¸ ì •ë ¬ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” íš¨ìœ¨ì ì¸ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. 

ì˜ì–´ë¥¼ ì˜ë¯¸ì  ì¤‘ê°„ ë‹¤ë¦¬(semantic pivot)ë¡œ í™œìš©í•˜ì—¬, ê¸°ì¡´ CLIPì˜ ê°•ë ¥í•œ ì‹œê° í‘œí˜„ ëŠ¥ë ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ í•œêµ­ì–´ ì§ˆì˜ì— ëŒ€í•œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ë¶„ë¥˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ë°©ë²•ë¡ 

HanCLIPì€ ì´ë¯¸ì§€â€“í•œêµ­ì–´ ê°„ ì§ì ‘ì ì¸ ì •ë ¬ ì—†ì´, **ì˜ì–´ë¥¼ ì˜ë¯¸ì  ë§¤ê°œì²´(semantic pivot)**ë¡œ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€â€“í•œêµ­ì–´ í‘œí˜„ ê°„ **ê³µìœ  ì„ë² ë”© ê³µê°„(shared embedding space)**ì„ í•™ìŠµí•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.

![Overall Architecture](asset/pipeline.png)

### Architecture Components

1. **Frozen Image Encoder**: CLIP ViT-B/32  
2. **Frozen Multilingual Text Encoder**: MiniLM-L12  
3. **Trainable Projection Heads**: fâ‚(Â·), fâ‚‚(Â·)

---

### Input êµ¬ì„±

- **ì˜ì–´ Text Query**: *eáµ¢*
  - *eáµ¢á´µ*: CLIP Text Encoderë¡œë¶€í„° ì¶”ì¶œëœ ì˜ì–´ ì„ë² ë”©
  - *eáµ¢á´·*: Multilingual Text Encoderë¡œë¶€í„° ì¶”ì¶œëœ ì˜ì–´ ì„ë² ë”©

- **ì´ë¯¸ì§€ ë©”ëª¨ë¦¬**: *V = {vâ‚, ..., vâ‚™}*  
  - CLIP Image Encoderë¡œ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì„ë² ë”©

- **í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë©”ëª¨ë¦¬**: *K = {kâ‚, ..., kâ‚˜}*  
  - Multilingual Encoderë¡œ ì „ì²˜ë¦¬ëœ í•œêµ­ì–´ ì„ë² ë”©

---

### Semantic Enhancement

- ì´ë¯¸ì§€ ì¿¼ë¦¬ ë° í•œêµ­ì–´ ì¿¼ë¦¬ë¡œë¶€í„° **pseudo image** *váµ¢á´µ*, **pseudo Korean text** *káµ¢á´·* ìƒì„±  
- Softmax-weighted aggregationìœ¼ë¡œ ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ì—ì„œ í‘œí˜„ ë³´ì™„

![Cross-modal and Cross-lingual Semantic Enhancement](asset/semantic_enhancement.png)

- ê° ì„ë² ë”©ì— **ë…¸ì´ì¦ˆ ì¶”ê°€ ë° L2 ì •ê·œí™”** ìˆ˜í–‰:

![Perturbed Embedding Semantic Enhancement](asset/noise_perturb.png)

---

### Inter-alignment Loss

- 4ê°€ì§€ ì„ë² ë”©ì„ ê°ê° projection headì— í†µê³¼:

```
Ãªáµ¢á´µ = fâ‚(~eáµ¢á´µ)  
Ãªáµ¢á´· = fâ‚‚(~eáµ¢á´·)  
vÌ‚áµ¢á´µ = fâ‚(~váµ¢á´µ)  
kÌ‚áµ¢á´· = fâ‚‚(~káµ¢á´·)
```

- ë‘ ìŒ (image-text)ì˜ **symmetric contrastive loss** ì ìš©

![Text-text Inter-alignment Loss](asset/text_inter.png)  
![pseudo image-Korean Inter-alignment Loss](asset/pseudo_inter.png)

- ìµœì¢… Inter-alignment Loss

```
ğ“› = ğ“›_text + ğ“›_pseudo
```
---

### Intra-alignment Loss

- **ëª¨ë‹¬ë¦¬í‹° ê°„ ê²©ì°¨(modality gap)**ë¥¼ ì¤„ì´ê¸° ìœ„í•´ attractive termë§Œ ì‚¬ìš©  
- ë™ì¼ ì˜ë¯¸ì˜ ìŒ ê°„ ê±°ë¦¬ ìµœì†Œí™”

![Intra-alignment Loss](asset/intra.png)

---

### Total Loss

```
ğ“› = ğ“›_inter + Î» Ã— ğ“›_intra
```

---

### Training Details

- ëª¨ë“  ì¸ì½”ë”ëŠ” **Frozen**
- **Projection Head**ë§Œ í•™ìŠµ
- í•™ìŠµ ì‹œ Gaussian noise + normalization â†’ generalization ë° í‘œí˜„ë ¥ í–¥ìƒ

---


## í™˜ê²½ ì„¤ì •
environmentë¥¼ ìƒì„±í•˜ê³  ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ dependencyë“¤ì„ ì„¤ì¹˜

  ```
    conda create -n env_name python=3.9
    conda activate env_name
    pip install -r requirements.txt
  ```

## ì‚¬ìš© ë°©ë²•
### 1. Quantitative retrieval result (Recall@K)
  ```
    # MSCOCO-Korean ë°ì´í„°ì…‹ì— ëŒ€í•œ retrieval result
    python retrieval_quan_cc3m.py

    # KoCC3M ë°ì´í„°ì…‹ì— ëŒ€í•œ retrieval result
    python retrieval_quan_mscoco.py
  ```
  - ì‹¤í–‰ ì‹œ hanclip, multilingual_clip, koclipì— ëŒ€í•œ ê²°ê³¼ metric í‘œì‹œ

### 2. Quantitative classification result (F1 score)
  ```
    sh classification.sh
  ```
  - ìœ„ íŒŒì¼ì—ì„œ --datasetì„ cifar10, stl10, caltech101, cifar100 ìœ¼ë¡œ ë°”ê¿”ì„œ ì‹¤í–‰
  - ìœ„ íŒŒì¼ì—ì„œ --modelì„ hanclip, multilingual_clip, koclip ìœ¼ë¡œ ë°”ê¿”ì„œ ì‹¤í–‰

### 3. Qualitative retrieval result
  ```
    python retrieval_img.py
  ```
  - ìœ„ íŒŒì¼ì—ì„œ query_textë¥¼ ì›í•˜ëŠ” ë¬¸ì¥ìœ¼ë¡œ ìˆ˜ì •ê°€ëŠ¥
  - í•´ë‹¹ query_textì— ëŒ€í•œ top10 ì´ë¯¸ì§€ retrieval ê²°ê³¼ê°€ {idx}_{query_text}.png í˜•ì‹ìœ¼ë¡œ ì €ì¥ë¨

### 4. Inference time 
  ```
    python inference_time.py
  ```

### 5. Visualization of cosine simalarity
  ```
    python visualization_cossim.py
  ```
  - ì‹¤í–‰ ì‹œ hanclip, multilingual_clip, koclipì— ëŒ€í•œ ê²°ê³¼ê°€ ê°ê° cosine_similarity_{model_name}.png ë¡œ ì €ì¥ë¨

### 6. Visualization of image embedding
  ```
    python visualization_imgemb.py
  ```
  - ì‹¤í–‰ ì‹œ hanclip, clip, koclipì— ëŒ€í•œ ê²°ê³¼ê°€ ê°ê° cifar10_umap_{model_name}.png ë¡œ ì €ì¥ë¨

## ì˜ˆì‹œ ê²°ê³¼
### 1. Quantitative retrieval result (Recall@K)
![Retrieval Result](asset/retrieval_quan.png)

### 2. Quantitative classification result (F1 score)
![Classification Result](asset/classification.png)

### 3. Qualitative retrieval result
![Retrieval Result Image](asset/qualitative_result.png)

### 4. Inference time 
![Inference Time Result](asset/inference_time.png)

### 5. Visualization of cosine simalarity
![Cosine Similarity Visualization](asset/cosine_similarity_result.png)

### 6. Visualization of image embedding
![Image Embedding Visualization](asset/image_emb_result.png)

## íŒ€ì›

  | íŒ€ì›                            | ì—­í•                                        |
| ----------------------------- | ---------------------------------------- |
| [ë¬¸ìŠ¹ê¸°](https://github.com/moon44432) |    Dataset curation, Architecture figure, Evaluation   |
| [ì„±ìœ ì§„](https://github.com/dinyudin203)      |    Dataset curation, Train, Evaluation    |
| [ì‹ ë™í˜„](https://github.com/Donghyun1228)     |    Dataset curation, Train(Overall), Evaluation    |
| [ì •ë‹¤í˜„](https://github.com/dhyun22)        |    Dataset curation, Paper writing, Analysis    |
